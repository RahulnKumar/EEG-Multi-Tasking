{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA/rahul_1911mt11/multi-tasking/EEG-Multi-Tasking\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random\n",
    "import traceback\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "episodes = 100\n",
    "num_epochs = 5\n",
    "num_classes = 2\n",
    "batch_size = 20\n",
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import multi_task_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3480, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_train = df.head(2500).reset_index(drop = True)\n",
    "df_test = df.tail(980).reset_index(drop = True)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels):\n",
    "    '''Convolution Block of 3x3 kernels + batch norm + maxpool of 2x2'''\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 5, padding=2),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "def set_grad(model, grad):\n",
    "    for param in model.parameters():\n",
    "#         print(param.shape)\n",
    "        param.requires_grad = grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_task_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(multi_task_model, self).__init__()\n",
    "\n",
    "        self.conv1 = conv_block(1, 20)\n",
    "        self.conv2 = conv_block(20, 40)\n",
    "        self.conv3 = conv_block(40, 60)        \n",
    "        self.fc =  nn.Linear(9 * 4 * 60, 100 )    \n",
    "        \n",
    "        #heads\n",
    "        self.y1o = nn.Linear(100,2)\n",
    "        self.y2o = nn.Linear(100,2)\n",
    "        self.y3o = nn.Linear(100,2)\n",
    "        self.y4o = nn.Linear(100, 2)\n",
    "        self.y5o = nn.Linear(100, 2)\n",
    "        self.y6o = nn.Linear(100,2)\n",
    "        self.y7o = nn.Linear(100, 2)\n",
    "        self.y8o = nn.Linear(100, 2)\n",
    "        self.y9o = nn.Linear(100, 2)\n",
    "        \n",
    "    def freeze(self, subject):\n",
    "        set_grad(self.y1o, False)\n",
    "        set_grad(self.y2o, False)\n",
    "        set_grad(self.y3o, False)\n",
    "        set_grad(self.y4o, False)\n",
    "        set_grad(self.y5o, False)\n",
    "        set_grad(self.y6o, False)\n",
    "        set_grad(self.y7o, False)\n",
    "        set_grad(self.y8o, False)\n",
    "        set_grad(self.y9o, False)\n",
    "        \n",
    "        if subject==1:\n",
    "            set_grad(self.y1o, True)\n",
    "        if subject==2:\n",
    "            set_grad(self.y2o, True)\n",
    "        if subject==3:\n",
    "            set_grad(self.y3o, True)\n",
    "        if subject==4:\n",
    "            set_grad(self.y4o, True)\n",
    "        if subject==5:\n",
    "            set_grad(self.y5o, True)\n",
    "        if subject==6:\n",
    "            set_grad(self.y6o, True)\n",
    "        if subject==7:\n",
    "            set_grad(self.y7o, True)\n",
    "        if subject==8:\n",
    "            set_grad(self.y8o, True)\n",
    "        if subject==9:\n",
    "            set_grad(self.y9o, True)\n",
    "            \n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "#         print('head shape ',x.shape)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x1 = self.fc(x)\n",
    "        \n",
    "        # heads\n",
    "        out1 = self.y1o(x1)\n",
    "        out2 = self.y2o(x1)\n",
    "        out3 = self.y3o(x1)\n",
    "        out4 = self.y4o(x1)\n",
    "        out5 = self.y5o(x1)\n",
    "        out6 = self.y6o(x1)\n",
    "        out7 = self.y7o(x1)\n",
    "        out8 = self.y8o(x1)\n",
    "        out9 = self.y9o(x1)\n",
    "                \n",
    "        #y5o = torch.sigmoid(self.y5o(x1)) #should be sigmoid\n",
    "#         print('Losses = ',y4o, '\\n')\n",
    "        return out1, out2, out3, out4, out5, out6, out7, out8, out9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------  EPISODE : 0  ----------------------\n",
      "Train Accuracy : 71.6304347826087 %\n",
      "Test Accuracy : 72.63888888888889 %\n",
      "-------------  EPISODE : 1  ----------------------\n",
      "Train Accuracy : 74.1304347826087 %\n",
      "Test Accuracy : 71.38888888888889 %\n",
      "-------------  EPISODE : 2  ----------------------\n",
      "Train Accuracy : 74.45652173913044 %\n",
      "Test Accuracy : 72.77777777777777 %\n",
      "-------------  EPISODE : 3  ----------------------\n",
      "Train Accuracy : 74.56521739130434 %\n",
      "Test Accuracy : 73.19444444444444 %\n",
      "-------------  EPISODE : 4  ----------------------\n",
      "Train Accuracy : 74.71014492753623 %\n",
      "Test Accuracy : 73.61111111111111 %\n",
      "-------------  EPISODE : 5  ----------------------\n",
      "Train Accuracy : 73.76811594202898 %\n",
      "Test Accuracy : 73.88888888888889 %\n",
      "-------------  EPISODE : 6  ----------------------\n",
      "Train Accuracy : 74.60144927536231 %\n",
      "Test Accuracy : 73.19444444444444 %\n",
      "-------------  EPISODE : 7  ----------------------\n",
      "Train Accuracy : 75.21739130434783 %\n",
      "Test Accuracy : 73.61111111111111 %\n",
      "-------------  EPISODE : 8  ----------------------\n",
      "Train Accuracy : 75.68840579710145 %\n",
      "Test Accuracy : 74.30555555555556 %\n",
      "-------------  EPISODE : 9  ----------------------\n",
      "Train Accuracy : 75.79710144927536 %\n",
      "Test Accuracy : 73.33333333333333 %\n",
      "-------------  EPISODE : 10  ----------------------\n",
      "Train Accuracy : 75.76086956521739 %\n",
      "Test Accuracy : 70.55555555555556 %\n",
      "-------------  EPISODE : 11  ----------------------\n",
      "Train Accuracy : 79.34782608695652 %\n",
      "Test Accuracy : 74.44444444444444 %\n",
      "-------------  EPISODE : 12  ----------------------\n",
      "Train Accuracy : 80.07246376811594 %\n",
      "Test Accuracy : 74.86111111111111 %\n",
      "-------------  EPISODE : 13  ----------------------\n",
      "Train Accuracy : 80.18115942028986 %\n",
      "Test Accuracy : 75.13888888888889 %\n",
      "-------------  EPISODE : 14  ----------------------\n",
      "Train Accuracy : 81.3768115942029 %\n",
      "Test Accuracy : 73.47222222222223 %\n",
      "-------------  EPISODE : 15  ----------------------\n",
      "Train Accuracy : 80.76086956521739 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "-------------  EPISODE : 16  ----------------------\n",
      "Train Accuracy : 80.6159420289855 %\n",
      "Test Accuracy : 75.41666666666667 %\n",
      "-------------  EPISODE : 17  ----------------------\n",
      "Train Accuracy : 80.90579710144928 %\n",
      "Test Accuracy : 76.52777777777777 %\n",
      "-------------  EPISODE : 18  ----------------------\n",
      "Train Accuracy : 80.76086956521739 %\n",
      "Test Accuracy : 76.94444444444444 %\n",
      "-------------  EPISODE : 19  ----------------------\n",
      "Train Accuracy : 80.32608695652173 %\n",
      "Test Accuracy : 76.25 %\n",
      "-------------  EPISODE : 20  ----------------------\n",
      "Train Accuracy : 82.1376811594203 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "-------------  EPISODE : 21  ----------------------\n",
      "Train Accuracy : 80.72463768115942 %\n",
      "Test Accuracy : 73.33333333333333 %\n",
      "-------------  EPISODE : 22  ----------------------\n",
      "Train Accuracy : 83.07971014492753 %\n",
      "Test Accuracy : 74.44444444444444 %\n",
      "-------------  EPISODE : 23  ----------------------\n",
      "Train Accuracy : 81.1231884057971 %\n",
      "Test Accuracy : 73.75 %\n",
      "-------------  EPISODE : 24  ----------------------\n",
      "Train Accuracy : 83.76811594202898 %\n",
      "Test Accuracy : 74.58333333333333 %\n",
      "-------------  EPISODE : 25  ----------------------\n",
      "Train Accuracy : 83.91304347826087 %\n",
      "Test Accuracy : 74.44444444444444 %\n",
      "-------------  EPISODE : 26  ----------------------\n",
      "Train Accuracy : 83.84057971014492 %\n",
      "Test Accuracy : 76.38888888888889 %\n",
      "-------------  EPISODE : 27  ----------------------\n",
      "Train Accuracy : 83.47826086956522 %\n",
      "Test Accuracy : 75.55555555555556 %\n",
      "-------------  EPISODE : 28  ----------------------\n",
      "Train Accuracy : 83.8768115942029 %\n",
      "Test Accuracy : 77.08333333333333 %\n",
      "-------------  EPISODE : 29  ----------------------\n",
      "Train Accuracy : 84.02173913043478 %\n",
      "Test Accuracy : 76.66666666666667 %\n",
      "-------------  EPISODE : 30  ----------------------\n",
      "Train Accuracy : 84.1304347826087 %\n",
      "Test Accuracy : 77.08333333333333 %\n",
      "-------------  EPISODE : 31  ----------------------\n",
      "Train Accuracy : 84.02173913043478 %\n",
      "Test Accuracy : 76.25 %\n",
      "-------------  EPISODE : 32  ----------------------\n",
      "Train Accuracy : 84.09420289855072 %\n",
      "Test Accuracy : 76.25 %\n",
      "-------------  EPISODE : 33  ----------------------\n",
      "Train Accuracy : 84.02173913043478 %\n",
      "Test Accuracy : 76.38888888888889 %\n",
      "-------------  EPISODE : 34  ----------------------\n",
      "Train Accuracy : 83.40579710144928 %\n",
      "Test Accuracy : 72.63888888888889 %\n",
      "-------------  EPISODE : 35  ----------------------\n",
      "Train Accuracy : 85.18115942028986 %\n",
      "Test Accuracy : 76.66666666666667 %\n",
      "-------------  EPISODE : 36  ----------------------\n",
      "Train Accuracy : 85.97826086956522 %\n",
      "Test Accuracy : 75.83333333333333 %\n",
      "-------------  EPISODE : 37  ----------------------\n",
      "Train Accuracy : 85.2536231884058 %\n",
      "Test Accuracy : 73.19444444444444 %\n",
      "-------------  EPISODE : 38  ----------------------\n",
      "Train Accuracy : 86.34057971014492 %\n",
      "Test Accuracy : 76.94444444444444 %\n",
      "-------------  EPISODE : 39  ----------------------\n",
      "Train Accuracy : 86.26811594202898 %\n",
      "Test Accuracy : 77.08333333333333 %\n",
      "-------------  EPISODE : 40  ----------------------\n",
      "Train Accuracy : 86.19565217391305 %\n",
      "Test Accuracy : 77.22222222222223 %\n",
      "-------------  EPISODE : 41  ----------------------\n",
      "Train Accuracy : 86.48550724637681 %\n",
      "Test Accuracy : 75.27777777777777 %\n",
      "-------------  EPISODE : 42  ----------------------\n",
      "Train Accuracy : 86.23188405797102 %\n",
      "Test Accuracy : 76.66666666666667 %\n",
      "-------------  EPISODE : 43  ----------------------\n",
      "Train Accuracy : 86.26811594202898 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "-------------  EPISODE : 44  ----------------------\n",
      "Train Accuracy : 85.18115942028986 %\n",
      "Test Accuracy : 76.25 %\n",
      "-------------  EPISODE : 45  ----------------------\n",
      "Train Accuracy : 86.8840579710145 %\n",
      "Test Accuracy : 77.77777777777777 %\n",
      "-------------  EPISODE : 46  ----------------------\n",
      "Train Accuracy : 87.10144927536231 %\n",
      "Test Accuracy : 77.63888888888889 %\n",
      "-------------  EPISODE : 47  ----------------------\n",
      "Train Accuracy : 87.21014492753623 %\n",
      "Test Accuracy : 77.36111111111111 %\n",
      "-------------  EPISODE : 48  ----------------------\n",
      "Train Accuracy : 87.46376811594203 %\n",
      "Test Accuracy : 73.47222222222223 %\n",
      "-------------  EPISODE : 49  ----------------------\n",
      "Train Accuracy : 89.67391304347827 %\n",
      "Test Accuracy : 75.55555555555556 %\n",
      "-------------  EPISODE : 50  ----------------------\n",
      "Train Accuracy : 89.7463768115942 %\n",
      "Test Accuracy : 74.86111111111111 %\n",
      "-------------  EPISODE : 51  ----------------------\n",
      "Train Accuracy : 89.67391304347827 %\n",
      "Test Accuracy : 76.25 %\n",
      "-------------  EPISODE : 52  ----------------------\n",
      "Train Accuracy : 88.22463768115942 %\n",
      "Test Accuracy : 76.38888888888889 %\n",
      "-------------  EPISODE : 53  ----------------------\n",
      "Train Accuracy : 88.69565217391305 %\n",
      "Test Accuracy : 76.25 %\n",
      "-------------  EPISODE : 54  ----------------------\n",
      "Train Accuracy : 87.68115942028986 %\n",
      "Test Accuracy : 76.38888888888889 %\n",
      "-------------  EPISODE : 55  ----------------------\n",
      "Train Accuracy : 88.65942028985508 %\n",
      "Test Accuracy : 76.25 %\n",
      "-------------  EPISODE : 56  ----------------------\n",
      "Train Accuracy : 88.91304347826087 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "-------------  EPISODE : 57  ----------------------\n",
      "Train Accuracy : 89.60144927536231 %\n",
      "Test Accuracy : 72.91666666666667 %\n",
      "-------------  EPISODE : 58  ----------------------\n",
      "Train Accuracy : 89.8913043478261 %\n",
      "Test Accuracy : 76.52777777777777 %\n",
      "-------------  EPISODE : 59  ----------------------\n",
      "Train Accuracy : 90.72463768115942 %\n",
      "Test Accuracy : 77.22222222222223 %\n",
      "-------------  EPISODE : 60  ----------------------\n",
      "Train Accuracy : 88.58695652173913 %\n",
      "Test Accuracy : 76.38888888888889 %\n",
      "-------------  EPISODE : 61  ----------------------\n",
      "Train Accuracy : 90.28985507246377 %\n",
      "Test Accuracy : 76.66666666666667 %\n",
      "-------------  EPISODE : 62  ----------------------\n",
      "Train Accuracy : 90.14492753623189 %\n",
      "Test Accuracy : 73.61111111111111 %\n",
      "-------------  EPISODE : 63  ----------------------\n",
      "Train Accuracy : 91.9927536231884 %\n",
      "Test Accuracy : 75.55555555555556 %\n",
      "-------------  EPISODE : 64  ----------------------\n",
      "Train Accuracy : 90.90579710144928 %\n",
      "Test Accuracy : 77.91666666666667 %\n",
      "-------------  EPISODE : 65  ----------------------\n",
      "Train Accuracy : 90.68840579710145 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "-------------  EPISODE : 66  ----------------------\n",
      "Train Accuracy : 92.5 %\n",
      "Test Accuracy : 75.83333333333333 %\n",
      "-------------  EPISODE : 67  ----------------------\n",
      "Train Accuracy : 92.57246376811594 %\n",
      "Test Accuracy : 76.94444444444444 %\n",
      "-------------  EPISODE : 68  ----------------------\n",
      "Train Accuracy : 92.02898550724638 %\n",
      "Test Accuracy : 76.94444444444444 %\n",
      "-------------  EPISODE : 69  ----------------------\n",
      "Train Accuracy : 92.3913043478261 %\n",
      "Test Accuracy : 76.80555555555556 %\n",
      "-------------  EPISODE : 70  ----------------------\n",
      "Train Accuracy : 92.06521739130434 %\n",
      "Test Accuracy : 76.38888888888889 %\n",
      "-------------  EPISODE : 71  ----------------------\n",
      "Train Accuracy : 93.84057971014492 %\n",
      "Test Accuracy : 75.13888888888889 %\n",
      "-------------  EPISODE : 72  ----------------------\n",
      "Train Accuracy : 93.33333333333333 %\n",
      "Test Accuracy : 76.66666666666667 %\n",
      "-------------  EPISODE : 73  ----------------------\n",
      "Train Accuracy : 94.27536231884058 %\n",
      "Test Accuracy : 75.27777777777777 %\n",
      "-------------  EPISODE : 74  ----------------------\n",
      "Train Accuracy : 93.84057971014492 %\n",
      "Test Accuracy : 75.27777777777777 %\n",
      "-------------  EPISODE : 75  ----------------------\n",
      "Train Accuracy : 93.6231884057971 %\n",
      "Test Accuracy : 76.52777777777777 %\n",
      "-------------  EPISODE : 76  ----------------------\n",
      "Train Accuracy : 93.55072463768116 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "-------------  EPISODE : 77  ----------------------\n",
      "Train Accuracy : 92.89855072463769 %\n",
      "Test Accuracy : 73.75 %\n",
      "-------------  EPISODE : 78  ----------------------\n",
      "Train Accuracy : 95.18115942028986 %\n",
      "Test Accuracy : 75.55555555555556 %\n",
      "-------------  EPISODE : 79  ----------------------\n",
      "Train Accuracy : 93.80434782608695 %\n",
      "Test Accuracy : 76.94444444444444 %\n",
      "-------------  EPISODE : 80  ----------------------\n",
      "Train Accuracy : 93.98550724637681 %\n",
      "Test Accuracy : 76.80555555555556 %\n",
      "-------------  EPISODE : 81  ----------------------\n",
      "Train Accuracy : 94.27536231884058 %\n",
      "Test Accuracy : 77.5 %\n",
      "-------------  EPISODE : 82  ----------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 77.91666666666667 %\n",
      "-------------  EPISODE : 83  ----------------------\n",
      "Train Accuracy : 94.23913043478261 %\n",
      "Test Accuracy : 76.80555555555556 %\n",
      "-------------  EPISODE : 84  ----------------------\n",
      "Train Accuracy : 94.23913043478261 %\n",
      "Test Accuracy : 77.08333333333333 %\n",
      "-------------  EPISODE : 85  ----------------------\n",
      "Train Accuracy : 96.08695652173913 %\n",
      "Test Accuracy : 75.83333333333333 %\n",
      "-------------  EPISODE : 86  ----------------------\n",
      "Train Accuracy : 95.94202898550725 %\n",
      "Test Accuracy : 77.77777777777777 %\n",
      "-------------  EPISODE : 87  ----------------------\n",
      "Train Accuracy : 93.6231884057971 %\n",
      "Test Accuracy : 76.66666666666667 %\n",
      "-------------  EPISODE : 88  ----------------------\n",
      "Train Accuracy : 95.94202898550725 %\n",
      "Test Accuracy : 78.75 %\n",
      "-------------  EPISODE : 89  ----------------------\n",
      "Train Accuracy : 95.0 %\n",
      "Test Accuracy : 77.77777777777777 %\n",
      "-------------  EPISODE : 90  ----------------------\n",
      "Train Accuracy : 96.66666666666667 %\n",
      "Test Accuracy : 78.05555555555556 %\n",
      "-------------  EPISODE : 91  ----------------------\n",
      "Train Accuracy : 95.28985507246377 %\n",
      "Test Accuracy : 78.19444444444444 %\n",
      "-------------  EPISODE : 92  ----------------------\n",
      "Train Accuracy : 95.03623188405797 %\n",
      "Test Accuracy : 77.08333333333333 %\n",
      "-------------  EPISODE : 93  ----------------------\n",
      "Train Accuracy : 95.1086956521739 %\n",
      "Test Accuracy : 76.66666666666667 %\n",
      "-------------  EPISODE : 94  ----------------------\n",
      "Train Accuracy : 95.47101449275362 %\n",
      "Test Accuracy : 75.0 %\n",
      "-------------  EPISODE : 95  ----------------------\n",
      "Train Accuracy : 94.23913043478261 %\n",
      "Test Accuracy : 76.66666666666667 %\n",
      "-------------  EPISODE : 96  ----------------------\n",
      "Train Accuracy : 95.21739130434783 %\n",
      "Test Accuracy : 77.08333333333333 %\n",
      "-------------  EPISODE : 97  ----------------------\n",
      "Train Accuracy : 97.17391304347827 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "-------------  EPISODE : 98  ----------------------\n",
      "Train Accuracy : 97.46376811594203 %\n",
      "Test Accuracy : 78.61111111111111 %\n",
      "-------------  EPISODE : 99  ----------------------\n",
      "Train Accuracy : 96.05072463768116 %\n",
      "Test Accuracy : 74.58333333333333 %\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "for episode in range(episodes):\n",
    "    n = random.randint(1,9)\n",
    "    df_train = df.loc[(df.Type=='train') & (df.Subject==n)].reset_index(drop = True)\n",
    "    train_dataset = multi_task_dataset(df_train)\n",
    "\n",
    "    # Data loader\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True)\n",
    "    try:\n",
    "        checkpoint = torch.load('model.pth', map_location=torch.device('cuda:1' if torch.cuda.is_available() else 'cpu'))\n",
    "        model = multi_task_model().to(device)\n",
    "        model.load_state_dict(checkpoint['weights'])\n",
    "        model = model.to(device)\n",
    "#         print('-------Trained model loaded-----------')\n",
    "    except :\n",
    "        traceback.print_exc()\n",
    "        model = multi_task_model()\n",
    "        model = model.to(device)\n",
    "        print('-------New model created --------------')\n",
    "\n",
    "\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels, subjects) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            subjects = subjects.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs[subjects[0].item()-1], labels)\n",
    "\n",
    "    #         model.freeze(subjects)\n",
    "    #         model.to(device)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            torch.save({'weights': model.state_dict()},'model.pth')\n",
    "            if (i+1) % 5000 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    print(f\"-------------  EPISODE : {episode}  ----------------------\")\n",
    "    print_training_accuracy()\n",
    "    print_testing_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model on train data\n",
    "def print_training_accuracy():\n",
    "    df_train = df.loc[(df.Type=='train') & (df.Subject!=10)].reset_index(drop = True)\n",
    "    train_dataset = multi_task_dataset(df_train)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=1, \n",
    "                                               shuffle=True)\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for image, label, subject in train_loader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(image)\n",
    "            _, predicted = torch.max(outputs[subject-1].data, 1)\n",
    "    #         print('predicted and label = ', predicted.item(), label.item())     \n",
    "\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    #         print(predicted, label.item())\n",
    "    # print(total, correct)\n",
    "    print('Train Accuracy : {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on test data\n",
    "def print_testing_accuracy():\n",
    "    df_test = df.loc[(df.Type=='test') & (df.Subject!=10)].reset_index(drop = True)\n",
    "    test_dataset = multi_task_dataset(df_test)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=1, \n",
    "                                               shuffle=True)\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for image, label, subject in test_loader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(image)\n",
    "            _, predicted = torch.max(outputs[subject-1].data, 1)\n",
    "    #         print('predicted and label = ', predicted.item(), label.item())     \n",
    "\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    #         print(predicted, label.item())\n",
    "    # print(total, correct)\n",
    "    print('Test Accuracy : {} %'.format(100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "75.97222222222223 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_gpu_memory_map():\n",
    "    \"\"\"Get the current gpu usage.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    usage: dict\n",
    "        Keys are device ids as integers.\n",
    "        Values are memory usage as integers in MB.\n",
    "    \"\"\"\n",
    "    result = subprocess.check_output(\n",
    "        [\n",
    "            'nvidia-smi', '--query-gpu=memory.used',\n",
    "            '--format=csv,nounits,noheader'\n",
    "        ], encoding='utf-8')\n",
    "    # Convert lines into a dictionary\n",
    "    gpu_memory = [int(x) for x in result.strip().split('\\n')]\n",
    "    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n",
    "    sorted_gpu_memory_map = dict(sorted(gpu_memory_map.items(), key=lambda item: item[1]))\n",
    "    return sorted_gpu_memory_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_gpu_memory_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 2153, 4: 3749, 1: 7294, 2: 10258, 0: 10585}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stats.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
