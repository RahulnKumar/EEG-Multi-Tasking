{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/DATA/rahul_1911mt11/multi-tasking/EEG-Multi-Tasking\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import torch \n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "gpu = \"cuda:1\"\n",
    "device = torch.device(gpu if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "episodes = 10\n",
    "num_epochs = 2\n",
    "num_classes = 2\n",
    "batch_size = 50\n",
    "lr = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import multi_task_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3480, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels):\n",
    "    '''Convolution Block of 3x3 kernels + batch norm + maxpool of 2x2'''\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 5, padding=2),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "    \n",
    "def set_grad(model, grad):\n",
    "    for param in model.parameters():\n",
    "#         print(param.shape)\n",
    "        param.requires_grad = grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_0(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Model_0, self).__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(1, 20)\n",
    "        self.conv2 = conv_block(20, 40)\n",
    "        self.conv3 = conv_block(40, 60)\n",
    "        \n",
    "        self.conv11 = conv_block(1, 20)\n",
    "        self.conv22 = conv_block(20, 40)\n",
    "        self.conv33 = conv_block(40, 60)\n",
    "        \n",
    "        self.fc = nn.Linear(9 * 4 * 60 * 2, 100)\n",
    "\n",
    "    \n",
    "       #heads\n",
    "        self.y1o = nn.Linear(100,2)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.conv2(x1)\n",
    "        x1 = self.conv3(x1)\n",
    "        \n",
    "        x2 = self.conv11(x)\n",
    "        x2 = self.conv22(x2)\n",
    "        x2 = self.conv33(x2)\n",
    "\n",
    "        # Features of shape (batch_size, 64)\n",
    "        feat1 = x1.reshape(x1.size(0), -1)\n",
    "        feat2 = x2.reshape(x2.size(0), -1)\n",
    "        feat  = torch.cat((feat1, feat2),1)\n",
    "        \n",
    "        head = self.fc(feat)\n",
    "  \n",
    "        # heads\n",
    "        out = self.y1o(head)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1(nn.Module):\n",
    "    def __init__(self, private_layers):\n",
    "        super(Model_1, self).__init__()\n",
    "        \n",
    "        self.x = private_layers\n",
    "#         self.conv1 = conv_block(1, 20)\n",
    "#         self.conv2 = conv_block(20, 40)\n",
    "#         self.conv3 = conv_block(40, 60)\n",
    "#         self.fc = nn.Linear(9 * 4 * 60 * 2, 100)\n",
    "#         #heads\n",
    "#         self.y1o = nn.Linear(100,2)\n",
    "        \n",
    "        # Loading shared layers\n",
    "        s_model = Model_map[0]\n",
    "        s_model = s_model().to(device)\n",
    "        try:\n",
    "            checkpoint = torch.load(f'models/shared_private/model_{0}.pth', map_location=torch.device(gpu if torch.cuda.is_available() else 'cpu'))\n",
    "            s_model.load_state_dict(checkpoint['weights'])\n",
    "            \n",
    "#             print(f'loaded shared layer for model {self.x}')\n",
    "        except:\n",
    "#             pdb.set_trace()\n",
    "            print(f\"------------Create a brand new shared layer from scrath -------------------------\")\n",
    "        self.conv11 = s_model.conv11\n",
    "        self.conv22 = s_model.conv22\n",
    "        self.conv33 = s_model.conv33\n",
    "        \n",
    "\n",
    "        # Loading private layers\n",
    "        p_model = Model_map[0]\n",
    "        p_model = p_model().to(device)\n",
    "        try:\n",
    "            checkpoint = torch.load(f'models/shared_private/model_{self.x}.pth', map_location=torch.device(gpu if torch.cuda.is_available() else 'cpu'))\n",
    "            p_model.load_state_dict(checkpoint['weights'])\n",
    "            \n",
    "#             print(f'loaded private layer for model {x}')\n",
    "        except:\n",
    "#             pdb.set_trace()\n",
    "#             print(f\"------------Create a brand new private layer for subject {self.x} from scrath -------------------------\")\n",
    "            pass\n",
    "    \n",
    "        self.conv1 = p_model.conv1\n",
    "        self.conv2 = p_model.conv2\n",
    "        self.conv3 = p_model.conv3\n",
    "        self.fc = p_model.fc\n",
    "        self.y1o = p_model.y1o\n",
    "        \n",
    "    \n",
    "    \n",
    "       \n",
    "      \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.conv2(x1)\n",
    "        x1 = self.conv3(x1)\n",
    "        \n",
    "        x2 = self.conv11(x)\n",
    "        x2 = self.conv22(x2)\n",
    "        x2 = self.conv33(x2)\n",
    "\n",
    "        # Features of shape (batch_size, 64)\n",
    "        feat1 = x1.reshape(x1.size(0), -1)\n",
    "        feat2 = x2.reshape(x2.size(0), -1)\n",
    "        feat  = torch.cat((feat1, feat2),1)\n",
    "        \n",
    "        head = self.fc(feat)\n",
    "  \n",
    "        # heads\n",
    "        out = self.y1o(head)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model_map = {0:Model_0, 1:Model_1, 2:Model_2, 3:Model_3, 4:Model_4, 5:Model_5, 6:Model_6, 7:Model_7, \n",
    "            8:Model_8, 9:Model_9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_map = {0:Model_0, 1:Model_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Episode : 0, n : 3, x : 0\n",
      "-------------  EPISODE : 0  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.42028985507247 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 1, n : 4, x : 3\n",
      "-------------  EPISODE : 1  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.27536231884058 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 2, n : 2, x : 4\n",
      "-------------  EPISODE : 2  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.27536231884058 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 3, n : 4, x : 2\n",
      "-------------  EPISODE : 3  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.27536231884058 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 4, n : 6, x : 4\n",
      "-------------  EPISODE : 4  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.27536231884058 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 5, n : 8, x : 6\n",
      "-------------  EPISODE : 5  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.3840579710145 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 6, n : 4, x : 8\n",
      "-------------  EPISODE : 6  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.42028985507247 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 7, n : 6, x : 4\n",
      "-------------  EPISODE : 7  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.42028985507247 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 8, n : 5, x : 6\n",
      "-------------  EPISODE : 8  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.42028985507247 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 9, n : 2, x : 5\n",
      "-------------  EPISODE : 9  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.34782608695652 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 10, n : 8, x : 2\n",
      "-------------  EPISODE : 10  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.3840579710145 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 11, n : 9, x : 8\n",
      "-------------  EPISODE : 11  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.34782608695652 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 12, n : 9, x : 9\n",
      "-------------  EPISODE : 12  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.3840579710145 %\n",
      "Test Accuracy : 76.25 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 13, n : 8, x : 9\n",
      "-------------  EPISODE : 13  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.34782608695652 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 14, n : 9, x : 8\n",
      "-------------  EPISODE : 14  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.34782608695652 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 15, n : 2, x : 9\n",
      "-------------  EPISODE : 15  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.4927536231884 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 16, n : 1, x : 2\n",
      "-------------  EPISODE : 16  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.4927536231884 %\n",
      "Test Accuracy : 75.83333333333333 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 17, n : 4, x : 1\n",
      "-------------  EPISODE : 17  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.4927536231884 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 18, n : 7, x : 4\n",
      "-------------  EPISODE : 18  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.4927536231884 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 19, n : 4, x : 7\n",
      "-------------  EPISODE : 19  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.4927536231884 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 20, n : 1, x : 4\n",
      "-------------  EPISODE : 20  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 21, n : 1, x : 1\n",
      "-------------  EPISODE : 21  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 22, n : 3, x : 1\n",
      "-------------  EPISODE : 22  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.4927536231884 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 23, n : 1, x : 3\n",
      "-------------  EPISODE : 23  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 24, n : 1, x : 1\n",
      "-------------  EPISODE : 24  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 25, n : 4, x : 1\n",
      "-------------  EPISODE : 25  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 26, n : 7, x : 4\n",
      "-------------  EPISODE : 26  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 27, n : 1, x : 7\n",
      "-------------  EPISODE : 27  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 76.25 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 28, n : 3, x : 1\n",
      "-------------  EPISODE : 28  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 29, n : 5, x : 3\n",
      "-------------  EPISODE : 29  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 30, n : 1, x : 5\n",
      "-------------  EPISODE : 30  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 31, n : 1, x : 1\n",
      "-------------  EPISODE : 31  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.4927536231884 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 32, n : 2, x : 1\n",
      "-------------  EPISODE : 32  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.42028985507247 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 33, n : 8, x : 2\n",
      "-------------  EPISODE : 33  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.45652173913044 %\n",
      "Test Accuracy : 76.11111111111111 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 34, n : 3, x : 8\n",
      "-------------  EPISODE : 34  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.56521739130434 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 35, n : 5, x : 3\n",
      "-------------  EPISODE : 35  ------------\n",
      "------------------------------------------------\n",
      "Train Accuracy : 94.4927536231884 %\n",
      "Test Accuracy : 75.97222222222223 %\n",
      "------------------------------------------------ \n",
      "\n",
      "Episode : 36, n : 3, x : 5\n",
      "-------------  EPISODE : 36  ------------\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-408e2f43d337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"-------------  EPISODE : {episode}  ------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mprint_training_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mprint_testing_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------------------------------------\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-4adb33a187f1>\u001b[0m in \u001b[0;36mprint_training_accuracy\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-20dc909abcc5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, private_layers)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Loading private layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'models/shared_private/model_{self.x}.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-e32ac4e8a03c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv33\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "x = 0\n",
    "for episode in range(episodes):\n",
    "    \n",
    "#     pdb.set_trace()\n",
    "    n = random.randint(1,9)\n",
    "#     n = 1\n",
    "    df_train = df.loc[(df.Type=='train') & (df.Subject==n)].reset_index(drop = True)\n",
    "    train_dataset = multi_task_dataset(df_train)\n",
    "\n",
    "    # Data loader\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True)\n",
    "    print(f\"Episode : {episode}, n : {n}, x : {x}\")\n",
    "    model = Model_map[1]\n",
    "    model = model(n).to(device)\n",
    "#     try:\n",
    "#         checkpoint = torch.load(f'models/shared_private/model_{n}.pth', map_location=torch.device(gpu if torch.cuda.is_available() else 'cpu'))\n",
    "#         model.load_state_dict(checkpoint['weights'])\n",
    "#         model = model.to(device)\n",
    "#     #         print('-------Trained model loaded-----------')\n",
    "#     except :\n",
    "         \n",
    "#         print(f'-------New  model_{n} created --------------')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "\n",
    "        for i, (images, labels, subjects) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            subjects = subjects.to(device)\n",
    "\n",
    "            # Forward pass 1\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "#             model1.freeze(subjects[0].item())\n",
    "#             model1.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Backward and optimize 1\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            torch.save({'weights': model.state_dict()},f'models/shared_private/model_{n}.pth')\n",
    "            torch.save({'weights': model.state_dict()},f'models/shared_private/model_{0}.pth')\n",
    "            if (i+1) % 500 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    print(f\"-------------  EPISODE : {episode}  ------------\")\n",
    "    print(\"------------------------------------------------\")\n",
    "    print_training_accuracy()\n",
    "    print_testing_accuracy()\n",
    "    print(\"------------------------------------------------\", '\\n')\n",
    "    \n",
    "    x = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_accuracy():\n",
    "    df = pd.read_csv('input/data.csv')\n",
    "    df_train = df.loc[(df.Type=='train') & (df.Subject!=10)].reset_index(drop = True)\n",
    "    train_dataset = multi_task_dataset(df_train)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=1, \n",
    "                                               shuffle=True)\n",
    "#     model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for image, label, subject in train_loader:\n",
    "            n = subject[0]\n",
    "            model = Model_map[1]\n",
    "            model = model(n).to(device)\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(image)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "    #         print('predicted and label = ', predicted.item(), label.item())     \n",
    "\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "#             print(predicted.item(), label.item())\n",
    "    # print(total, correct)\n",
    "    print('Train Accuracy : {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on test data\n",
    "def print_testing_accuracy():\n",
    "    df = pd.read_csv('input/data.csv')\n",
    "    df_test = df.loc[(df.Type=='test') & (df.Subject!=10)].reset_index(drop = True)\n",
    "    test_dataset = multi_task_dataset(df_test)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=1, \n",
    "                                               shuffle=True)\n",
    "#     model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for image, label, subject in test_loader:\n",
    "            n = int(subject[0])\n",
    "            model = Model_map[1]\n",
    "            model = model(n).to(device)\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(image)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "#             print('predicted and label = ', predicted.item(), label.item())     \n",
    "\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "#             print(predicted.item(), label.item())\n",
    "#     print(total, correct)\n",
    "    print('Test Accuracy : {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print_testing_accuracy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print_training_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}